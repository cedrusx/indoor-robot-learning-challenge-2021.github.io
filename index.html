---
layout: home
---
<head>
<style>
.user-details {
  text-align: center;
  width: 60%;
}

.permlinks {
  width:60%;
  padding-right: 20%;
  padding-left: 20%;
}

.user-details {
  text-align: center;
  width: 60%;
}

h2 {
  text-align: center;
}

.others {
    width:60%;
    padding-right: 20%;
    padding-left: 20%;
}

p {
  text-align: left;
}

li:not(:last-child) {
    margin-bottom: 1px;
}

table, th, td {
  font-size: 16px;
  border: 1px solid #B6B6B4;
  border-collapse: collapse;
  padding: 1px;
}

table.center {
  margin-left: auto;
  margin-right: auto;
}
</style>
</head>


<div class="user-details">
<h1> Introduction to Continuous Robotic Learning </h1>
    <img src="https://lifelong-robotic-vision.github.io/about/Relation.png" alt="Human-Robot-Computer" width="520">
    <p style="text-align: justify;"> More recently, service robots have emerged as a highlight for both academic and industrial field. Applications faced to public tend to be more mature, such as public service robots in locations such as airports and hotels, but developments are not limited to. There are even greater potential in applications that are more <strong><I>personal</I></strong>, <strong><I>private</I></strong>, and <strong><I>customized</I></strong>, such as home assistant, elderly care, smart retail etc. Beyond all the achievements, the long-time technology bottleneck is <strong><I>the lack of robot learning capability</I></strong>. That is, just the mainstream supervised learing (including Deep Learning) based on pre-annoated data is not good enough for robotic applications that requires learning continuously in <strong><I>preception</I></strong>, <strong><I>manipulation</I></strong>, and <strong><I>interaction with users</I></strong>. Indoor environment therefore provides an ideal environment for continuous learning, since robots therefore have opportunities interacting with their surroundings more effectively. </p>
    <p style="text-align: justify;"> The grand challenge aims to provide a platform that evaluates the latest progress of the field. The challenge is designed to have two perspectives: <strong><I>the perception/cognition</I></strong> and <strong><I>the physical tasks</I></strong>. Teams with different background in all releated fields are encouraged. This include but not limited to the field of robotics, machine learing, and computer vision. Collaborations are also strongly encouraged. We believe this grand challenge will have significant social, academical, and industrial achievement in future research, and paves a way to large-scale deployment of convinent service robot in the next 5 to 10 years. </p>
</div>


<div class="user-details">
<h1>Announcements</h1>
</div>

<div class="permlinks">
<dl>
	{% for post in site.posts limit:4 %}
	<dt><code>{{ post.date | date_to_string }} </code><i class="fas fa-angle-double-right" aria-hidden="true"></i>{{ post.title }}</a> &nbsp;
	{% if post.description %}
 <dd style="text-align: justify">{{ post.description | markdownify }}
    </dd>
	{% endif %}
	{% endfor %}
    <p> ... </p>
    <p> </p>
    <p style="text-align: justify;">Further information will be posted during the challenge.</p>
    <p style="text-align: justify;"> Please check this website for updates regularly for the lastest information! </p>
</dl>
</div>


<div class="user-details">
<h1>Comptetition Schedule</h1>
<p style="text-align: justify;">The competition schedule is as follows, will be updated later:</p>
{% include schedule.html %}
</div>





<div class="user-details">
<h1>Distributed Testing Sites</h1>
<p style="text-align: justify;"></p>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=05374d&w=290&t=tt&d=x7IWUg_YqbOmacnqED0RqqXqY6DRLCwhFJWMAFYteFw&co=d5d9db&ct=0f0101'></script><p style="text-align: justify;"> There will be multiple testing sites around the world for this competition. Each task force team is allowed to choose a testing site according to their own geographical position and complete on-site testings in about one week. </p>
<p style="text-align: justify;"> The potential testing sites are as follows (the confirmed ones are highlighted with light green): </p>
{% include testingSites.html %}
</div>


<div class="user-details">
<h1>Co-Organizations</h1>
<img src="https://indoor-robot-learning-challenge-2021.github.io/about/Co-Organizations.png" alt="Human-Robot-Computer" width="820">
</div>

<div class="user-details">
<h1>Co-Organizers</h1>
<img src="https://indoor-robot-learning-challenge-2021.github.io/co-organizers.png" alt="Human-Robot-Computer" width="820">
</div>



<div class = "user-details">
<h1>Acknowledgement</h1>
    <p style="text-align: justify;">This section will introduce the task force team, and anyone who contributed to the dataset and the Grand Challenge in general. To be announced later.</p>
    <p style="text-align: justify;">The website is created and maintained by <a href="mailto:yw446@cornell.edu">Cindy Wei</a> and <a href="mailto:yf94@cornell.edu">Agnes Feng</a>.</p>
    <p style="text-align: justify;">Special thanks to Yingkai Liu for such a great <a href="https://yk-liu.github.io/">website template</a>.</p>
</div>

<div class="user-details">
<h1>Further Reading</h1>
    <p style="text-align: justify;">This section will contain any related articles and recent news. To be updated later by the committee.</p>
</div>

<div class="user-details">
<h1>Join the Competition</h1>
    <p style="text-align: justify;">For joining our Grand Challenges on Indoor Robot Learning, please contact us via: <a href="mailto:yimin.zhang@intel.com">yimin.zhang@intel.com</a>. Thanks!</p>
</div>
